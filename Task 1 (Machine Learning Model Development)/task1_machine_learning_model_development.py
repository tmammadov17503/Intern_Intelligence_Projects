# -*- coding: utf-8 -*-
"""Task1_Machine_Learning_Model_Development.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zY0LO6doUMh43DmPDUTtfUUuAX0IgSPU

#Drive Mounting
"""

from google.colab import drive
drive.mount('/content/drive')

"""#Load Database

"""

import pandas as pd

file_path = "/content/drive/My Drive/Intern_Intelligence/Task(1)/WA_Fn-UseC_-Telco-Customer-Churn.csv"

df = pd.read_csv(file_path)

df.info()
df.head()

"""#Checking for Mssing Values and we convert needed datatypes

"""

df.isnull().sum()
df.dtypes

"""#Now we visualize the data"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x=df["Churn"])
plt.title("Churn Distribution")
plt.show()

"""#Yes and No values to 1/0 and converting other categorical columns"""

df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})
df = pd.get_dummies(df, drop_first=True)

"""#Normalization of Numerical Features"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
numeric_cols = ["tenure", "MonthlyCharges", "TotalCharges"]
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

print(df.columns)

df.columns = df.columns.str.strip()
print(df.columns)

df = pd.read_csv(file_path, delimiter=",", skipinitialspace=True)
print(df.head())

print(df.columns)

df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

print(df.isnull().sum())
df["TotalCharges"].fillna(df["TotalCharges"].median(), inplace=True)

binary_cols = ["Partner", "Dependents", "PhoneService", "PaperlessBilling", "Churn"]
for col in binary_cols:
    df[col] = df[col].map({"Yes": 1, "No": 0})

print(df.columns)

df.drop(columns=["customerID"], inplace=True)

binary_cols = ["Partner", "Dependents", "PhoneService", "PaperlessBilling", "Churn"]
for col in binary_cols:
    df[col] = df[col].map({"Yes": 1, "No": 0})

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
numeric_cols = ["tenure", "MonthlyCharges", "TotalCharges"]
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

from sklearn.model_selection import train_test_split

X = df.drop(columns=["Churn"])
y = df["Churn"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training set size:", X_train.shape)
print("Testing set size:", X_test.shape)

"""#Training of the model"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print(df.select_dtypes(include=['object']).columns)

df = pd.get_dummies(df, drop_first=True)

df["gender"] = df["gender"].map({"Female": 0, "Male": 1})

print(df.columns)

df.drop(columns=["gender_Female"], inplace=True, errors="ignore")

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

X = df.drop(columns=["Churn"])
y = df["Churn"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print(df.isnull().sum())
df.fillna(df.median(), inplace=True)
df.fillna(0, inplace=True)
df.dropna(inplace=True)

print(df.isnull().sum().sum())

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

X = df.drop(columns=["Churn"])
y = df["Churn"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print(y_train.value_counts())
print(y_test.value_counts())

print(df["Churn"].value_counts())

from sklearn.utils import resample

df_majority = df[df.Churn == 0]
df_minority = df[df.Churn == 1]

df_majority_downsampled = resample(df_majority,
                                   replace=False,
                                   n_samples=len(df_minority),
                                   random_state=42)

df_balanced = pd.concat([df_majority_downsampled, df_minority])

X = df_balanced.drop(columns=["Churn"])
y = df_balanced["Churn"]

print(df["Churn"].value_counts())

from sklearn.utils import resample

df_majority = df[df.Churn == 0]
df_minority = df[df.Churn == 1]

if len(df_minority) > 0:
    df_minority_upsampled = resample(df_minority,
                                     replace=True,
                                     n_samples=len(df_majority),
                                     random_state=42)

    df_balanced = pd.concat([df_majority, df_minority_upsampled])

    X = df_balanced.drop(columns=["Churn"])
    y = df_balanced["Churn"]

    print("After balancing:")
    print(y.value_counts())
else:
    print("No Churn=1 samples found. Check dataset preprocessing.")

print(df["Churn"].value_counts())

import pandas as pd

file_path = "/content/drive/My Drive/Intern_Intelligence/Task(1)/WA_Fn-UseC_-Telco-Customer-Churn.csv"
df = pd.read_csv(file_path)

print(df["Churn"].value_counts())

df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})

print(df["Churn"].value_counts())

print(df.columns)

print(df["Churn"].value_counts())

import pandas as pd

file_path = "/content/drive/My Drive/Intern_Intelligence/Task(1)/WA_Fn-UseC_-Telco-Customer-Churn.csv"
df = pd.read_csv(file_path)

print(df.columns)
print(df["Churn"].value_counts())

print(df["Churn"].unique())

df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})
print(df["Churn"].value_counts())

print(df["Churn"].isnull().sum())

df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})
print(df["Churn"].value_counts())

print(df["Churn"].unique())

import pandas as pd

file_path = "/content/drive/My Drive/Intern_Intelligence/Task(1)/WA_Fn-UseC_-Telco-Customer-Churn.csv"
df = pd.read_csv(file_path)

print(df["Churn"].value_counts())

df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})
print(df["Churn"].value_counts())

print(df.columns)

print(df["Churn"].unique())

print(df["Churn"].dtype)

print(df[["Churn"]].head(20))

df["Churn"] = df["Churn"].str.strip()
print(df["Churn"].unique())

print(df["Churn"].dtype)

df["Churn"] = df["Churn"].astype(int)
print(df["Churn"].value_counts())

print(df["Churn"].isnull().sum())

df["Churn"].fillna(df["Churn"].mode()[0], inplace=True)

print(df["Churn"].isnull().sum())
print(df["Churn"].dropna().unique())

import pandas as pd

file_path = "/content/drive/My Drive/Intern_Intelligence/Task(1)/WA_Fn-UseC_-Telco-Customer-Churn.csv"
df = pd.read_csv(file_path)

print(df["Churn"].value_counts())

df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})
print(df["Churn"].value_counts())

print(df.isnull().sum())

binary_cols = ["Partner", "Dependents", "PhoneService", "PaperlessBilling"]
for col in binary_cols:
    df[col] = df[col].map({"Yes": 1, "No": 0})

df = pd.get_dummies(df, columns=["InternetService", "Contract", "PaymentMethod"], drop_first=True)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
numeric_cols = ["tenure", "MonthlyCharges", "TotalCharges"]
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

print(df[numeric_cols].isnull().sum())

df["TotalCharges"].fillna(df["TotalCharges"].median(), inplace=True)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

df["TotalCharges"] = df["TotalCharges"].fillna(df["TotalCharges"].median())

X = df.drop(columns=["Churn"])
y = df["Churn"]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)

print(X.dtypes)

X = X.drop(columns=["customerID"])
binary_cols = ["gender", "MultipleLines", "OnlineSecurity", "OnlineBackup",
               "DeviceProtection", "TechSupport", "StreamingTV", "StreamingMovies"]

for col in binary_cols:
    X[col] = X[col].map({"Yes": 1, "No": 0, "No internet service": 0, "No phone service": 0})
X = pd.get_dummies(X, drop_first=True)
print(X.dtypes)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

print(X_train.isnull().sum())

X_train.fillna(X_train.median(), inplace=True)
X_test.fillna(X_test.median(), inplace=True)
X_train.dropna(inplace=True)
X_test.dropna(inplace=True)
y_train = y_train.loc[X_train.index]
y_test = y_test.loc[X_test.index]
model = LogisticRegression()
model.fit(X_train, y_train)

print(X_train.shape)
print(y_train.shape)

X_train.fillna(X_train.median(), inplace=True)
X_test.fillna(X_test.median(), inplace=True)
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

print(X_train.isnull().sum().sum())
print(X_test.isnull().sum().sum())
X_train.fillna(X_train.median(), inplace=True)
X_test.fillna(X_test.median(), inplace=True)

print(X_train.dtypes)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

import numpy as np

print("Missing values in X_train:", np.isnan(X_train).sum())
print("Missing values in X_test:", np.isnan(X_test).sum())

print("Infinite values in X_train:", np.isinf(X_train).sum())
print("Infinite values in X_test:", np.isinf(X_test).sum())

X_train = np.nan_to_num(X_train, nan=np.nanmedian(X_train))
X_test = np.nan_to_num(X_test, nan=np.nanmedian(X_test))

X_train = np.where(np.isinf(X_train), np.nanmedian(X_train), X_train)
X_test = np.where(np.isinf(X_test), np.nanmedian(X_test), X_test)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["No Churn", "Churn"], yticklabels=["No Churn", "Churn"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()